# Administraci√≥ Remota amb Ansible

# Prerequisits

Per desenvolupar aquesta pr√†ctica necessitar√†s tenir uns coneixements b√†sics sobre VirtualBox, Vagrant, Git (control de versions), OpenSSH, Docker i Docker Compose.

# Objectius (6 hores)

Entendre els conceptes d‚Äôadministraci√≥ remota de sistemes operatius en xarxa mitjan√ßant Ansible, que fa servir SSH per instal¬∑lar i configurar software en remot, permetent l‚Äôaprovisionament de m√†quines mitjan√ßant una sintaxi declarativa. Es contextualitzar√† la tecnologia Ansible en el marc DevOps que domina l‚Äôadministraci√≥ de sistemes en l‚Äôactualitat i es comparar√† amb la resta de competidors.

Al final de la pr√†ctica l‚Äôalumne haur√† estat capa√ß de poder aprovisionar de manera autom√†tica un cluster format per tres nodes, un en mode proxy invers fent el papel de load balancer, i dos com a servidors web. Totes tres m√†quines s‚Äôexecuten en contenidors Docker sobre i corren Apache sobre Ubuntu, gr√†cies a l‚Äôexecuci√≥ d‚Äôun *docker-compose*. L‚Äôentorn virtual on es muntar√† vindr√† donat per Vagrant fent VirtualBox com a prove√Ødor.

La il¬∑lustraci√≥ inferior mostra la topologia i les diferents fases en qu√® transcorrer√† la pr√†ctica. El port√†til representa la VM creada per Vagrant (*management node*), i els tres nodes del cl√∫ster s√≥n contenidors de Docker. Tots es troben a la mateixa xarxa de tipus bridge creada per Docker al docker-compose.yml. S‚Äôha de tenir present aquesta topologia durant tota la part pr√†ctica de l‚Äôactivitat.

![image alt text](images/image_0.png)

# Webgrafia

1. [QU√â ES ANSIBLE](https://www.youtube.com/watch?v=uqMkIdLE0AQ) üìπ (v√≠deo)

2. [https://sysadmincasts.com/episodes/43-19-minutes-with-ansible-part-1-4](https://sysadmincasts.com/episodes/43-19-minutes-with-ansible-part-1-4) üìπ + üìù

3. [An Ansible2 Tutorial](https://serversforhackers.com/c/an-ansible2-tutorial) üìù(tutorial)

4. [Infrastructure as Code: Chef, Ansible, Puppet, or Terraform?](https://www.ibm.com/cloud/blog/chef-ansible-puppet-terraform)  üìù

5. [What Is Ansible | Configuration Management With Ansible](https://www.edureka.co/blog/what-is-ansible/?utm_source=youtube&utm_medium=description-link&utm_campaign=id) üìπ + üìù

6. *[How To Setup Ansible Master-Slave and Install Apache Web Serve*r](https://blogs.tensult.com/2019/12/19/how-to-setup-ansible-master-slave-install-apache-web-server/) üìù

# Repositori GitHub

# Qu√® √©s Ansible?

*Ansible *√©s un software gestor de configuraci√≥ remota i una eina d‚Äôorquestraci√≥. Treballa com un motor d‚Äôautomatizaci√≥ IT, i aix√≤ vol dir fonamentalment que ajuda els *sysadmins *a fer desplegaments/aprovisionaments de manera remota.

√âs un projecte *open-source* que mant√© l‚Äôempresa *Ansible Inc.* i que va llen√ßar el 2012. Ara b√©, *Red Hat* va adquirir aquesta companyia el 2015, i tot i que Ansible continua sent open-source i gratu√Øt Red Hat ha creat altres productes de valor afegit al seu voltant com *Ansible Tower*.

Visualitza aquest [v√≠deo en castell√† de 6 min](https://www.youtube.com/watch?v=uqMkIdLE0AQ) i respon a les seg√ºents preguntes:

1. Com definiries amb les teves paraules el terme aprovisionament que es fa servir al v√≠deo. Pots posar un exemple.

*Respon*

2. Indica quin dels dos codis que veus en aquest exemple √©s declaratiu i per qu√®.

![image alt text](images/image_1.png)

*Respon*

3. El v√≠deo indica el car√†cter modular d‚ÄôAnsible i mostra la p√†gina amb el cat√†leg. Ens diuen que Ansible t√© un m√≤dul dedicat a la monitoritzaci√≥ del software Nagios que estigui instal¬∑lat en un m√†quina remota. Podries indicar captura de pantalla de la p√†gina d‚Äôaquest m√≤dul d‚ÄôAnsible?

*Respon*

4. √âs possible executar Ansible sobre un Windows?

*Respon*

5. Com es diu el creador d‚ÄôAnsible?

*Respon*

6. Sobre la diapositiva que apareix per al min 5:28. Mirant la nostra topologia. Quin √©s el controlador i quins els nodes?

*Respon*

## Declaratiu vs Imperatiu

Llegeix aquesta definici√≥ de programaci√≥ imperativa i declarativa aplicada a DevOps, i que tamb√© aplica a Ansible:

<table>
  <tr>
    <td>DevOps paradigms (Declarative vs Imperative)

An automation framework can be designed and implemented in two different ways:imperative vs declarative . These are called DevOps paradigms. 

While using an imperative paradigm, the user is responsible for defining exact steps which are necessary to achieve the end goal, such as instructions for software installation, configuration, database creation, etc. Those steps are later executed in a fully automated way. The ultimate state of the environment is a result of particular operations defined by the user. While keeping full control over the automation framework, users have to carefully plan every step and the sequence in which they are executed. Although suitable for small deployments, imperative DevOps does not scale and fails while deploying big software environments, such as OpenStack.

In turn, a declarative paradigm takes a different approach. Instead of defining exact steps to be executed, the ultimate state is defined. The user declares how many machines will be deployed, will workloads be virtualised or containerised, which applications will be deployed, how will they be configured, etc. However, the user does not define the steps to achieve it. Instead, a ‚Äòmagic‚Äô code is executed which takes care of all necessary operations to achieve the desired end state. By choosing a declarative paradigm, users not only save a lot of time usually spent on defining the exact steps but also benefit from the abstraction layer being introduced. Instead of focusing on the ‚Äòhow‚Äô, they can focus on the ‚Äòwhat‚Äô.
Font: https://ubuntu.com/blog/declarative-vs-imperative-devops-done-right
</td>
  </tr>
</table>


Observa aquesta il¬∑lustraci√≥ i raona quina metodologia, dreta o esquerra, pertany a la declarativa i per qu√®.

![image alt text](images/image_2.png)

7. Retalla i enganxa cadascuna d‚Äôaquestes expressions (s√≥n idees o b√© tecnologies d‚Äôun o altre tipus) en una o altra columna. **Ves afegint files a la taula segons necessitis**:

* Bash script

* Terraform

* Perform step-by-step tasks and manage changes in state

* Describe what you want as and end result

* SQL

* Ansible

* C

* C++

* Explicit instruction

* Describe the outcome

* The system is smart, you don‚Äôt care

* The system is stupid, you are smart

* Tell what, not how

* Tell what and tell how

*Emplena*

<table>
  <tr>
    <td>DECLARATIU</td>
    <td>IMPERATIU </td>
  </tr>
  <tr>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>...</td>
    <td>...</td>
  </tr>
</table>


## Infrastructure as Code

*Parlem de tecnologies Infrastructure as Code als processos de gesti√≥ d‚Äôaprovisionament de data centers a trav√©s de fitxers de definici√≥ llegibles per una m√†quina, m√©s aviat que per l‚Äô√∫s d‚Äôeines de configuraci√≥ interactives.*[Wikipedia]

Per exemple, deixant de banda els scripts bash que hi puguem afegir, el fitxer *Vagrantfile *√©s un exemple de metodologia declarativa. Penseu com √©s de f√†cil canviar de *provisioner *(de VBox a AWS, per ex.) sense donar cap instrucci√≥!

Fins i tot, dintre de la part *provision *de Vagrant, si afegeixes una l√≠nia i tornes a executar vagrant provision, veur√†s que Vagrant no executar√† tot el codi, sin√≥ tan sols la l√≠nia afegida.

*Dockerfile *tamb√© √©s un exemple de IaC ([per saber m√©s](https://rancher.com/containers-making-infrastructure-code-easier)) i Cloudformation i Terraform tamb√© ho s√≥n. Altres exemples d‚ÄôIaC s√≥n les pipelines de Jenkins (atenci√≥, les *pipelines *amb codi declaratiu que vam veure a la pr√†ctica, no les d‚Äôscripting, que s√≥n imperatives). A Kubernetes aquesta difer√®ncia tamb√© es troba ben establerta i pots crear objectes tant de forma imperativa, b√†sicament des de la CLI, com declarativa (i en aquest cas ofereix la possibilitat de fer-ho amb el mateix llenguatge que fem servir a Ansible: YAML).

## Competidors d‚ÄôAnsible en l‚Äôautomatitzaci√≥ IT

![image alt text](images/image_3.png)

No tractarem d‚Äôells de forma espec√≠fica els altres programes que veus a la il¬∑lustraci√≥ i que tamb√© es fan servir per aprovisionar i automatitzar tasques en servidors, per√≤ s√≠ que conv√© saber que un dels grans avantatges que presenta Ansible respecte tots ells: Ansible √©s *agentless*, aix√≤ vol dir que no necessita de la instal¬∑laci√≥ de cap software espec√≠fic propi en els servidors remots. Aix√≤ s√≠, necessitaran Python. Puppet (2005) √©s m√©s antic que Ansible, per√≤ aquest t√© l‚Äôimpuls de Red Hat. Sense entrar en els detalls de la resta de programes, aquests s√≥n els punts forts d‚ÄôAnsible:

* **Agentless**, no requereix de software propi als servidors remots (b√© nom√©s Python, per√≤ aix√≤ no √©s propi d‚ÄôAnsible).

* Instal¬∑laci√≥ molt f√†cil i a m√©s amb alternatives (apt, pip)

* Configuraci√≥ declarativa amb YAML (un llenguatge de formateig ben conegut)

* Configuraci√≥ per PUSH (√©s el servidor central qui s‚Äôencarrega de donar les ordres d‚Äôautomatitzaci√≥ als nodes remots).

![image alt text](images/image_4.png)

## Com s‚Äôinstal¬∑la Ansible?

Deixant de banda instal¬∑lacions basades en la compilaci√≥ del codi font, podem instal¬∑lar directament amb el **gestor de paquets** d‚ÄôUbuntu (o qualsevol altra distribuci√≥ que els suporti) de la seg√ºent manera:

$ sudo apt update

$ sudo apt install ansible

Si volem obtenir la versi√≥ m√©s actualitzada es pot carregar primer el repositori oficial:

$ sudo add-apt-repository ppa:ansible/ansible

i a continuaci√≥ executem les dues mateixes comandes anteriors.

Un altre m√®tode alternatiu: com que Ansible est√† escrit amb Python, tamb√© suporta la instal¬∑laci√≥ mitjan√ßant el gestor de paquets **pip**.

$ sudo pip install ansible

Per comprovar que la instal¬∑laci√≥ ha estat correcta escriu ansible sobre la consola, i comprova que el programa et mostra el contingut de l‚Äôajuda amb les diferents opcions disponibles.

Pots repassar el proc√©s d‚Äôinstal¬∑laci√≥ d‚ÄôAnsible en [aquest v√≠deo](https://www.youtube.com/watch?v=Zimn-UCbQ0A)  üìπ de 6 min per si t‚Äôha queda cap dubte.

# Fes-ho tu mateix! üí™

Tal i com indica la primera il¬∑lustraci√≥, la de la topologia, l‚Äôentorn d‚Äôaprenentatge d‚ÄôAnsible suposa tenir a l‚Äôabast una infrastructura formada per un ordinador controlador (*management node*) i els remots sobre els que opera dins la mateixa xarxa.

Per tal d‚Äôemular un entorn on aprendre **treballarem amb una m√†quina virtual Ubuntu creada sobre Vagrant**, que portar√† instal¬∑lada Docker. Un script de **Docker Compose** ens permetr√† arrencar els tres nodes en mode bridge dintre de la m√†quina virtual, sobre els quals Ubuntu far√† de manager (ser√† aqu√≠ on instal¬∑larem Ansible).

Crearem un projecte d‚ÄôAnsible que permeti desplegar de manera automatitzada, en aquests tres nodes, dos servidors webs Apache amb un altre  a davant, tamb√© Apache, configurat en mode **proxy invers**, de forma que vagi repartint la c√†rrega de les peticions web entre els altres dos nodes.

## Clona el repositori

Executa sudo su

Clona el repositori que cont√© el codi base a partir del qual crear el nostre entorn dins la carpeta /root (no ho facis, o almenys no executis, a /vagrant perqu√® hi ha problemes de permisos en estar compartida amb Windows). Sempre estarem a /root.

*Indica la comanda amb qu√® has clonat el projecte.*

*Observa el Vagrantfile. Quina mem√≤ria RAM requerir√† la VM que instanciar√†s. Quantes CPU*? Ajusta els par√†metres al teu equipament, per√≤ tingues en compte que hauria de tenir m√≠nim 2GB de RAM.

*Quin sistema operatiu fa servir la VM?*

## Arrenca la VM Vagrant i instal¬∑la Ansible

Arrenca la VM amb vagrant up. Entra a ella mitjan√ßant la comanda que inclou ssh.

*Amb quina comanda entres a la VM que acabes de crear?*

Instal¬∑la Ansible amb el gestor de paquets tal i com s‚Äôha indicat anteriorment. No oblidis actualitzar els repositoris per obtenir la versi√≥ m√©s moderna.

*Mostra captura de pantalla on s‚Äôindica la versi√≥ de l‚ÄôAnsible instal¬∑lada.*

## Creaci√≥ imatge Docker ubuntu-ssh

Els contenidors que faran de nodes remots fan servir una imatge d‚ÄôUbuntu especialment preparada per tal de ser operativa des del punt de vista servidor SSH, que √©s el que necessita el controlador d‚ÄôAnsible per tal de comunicar-se amb ella.

I aquests contenidors els instanciar√†s a partir d‚Äôuna imatge que construir√†s en el teu sistema a partir del Dockerfile que trobar√†s a la carpeta /docker-env del repositori. Observa aquest fitxer i respon:

*Escriu la l√≠nia del fitxer Dockerfile que indica el fus horari que tindran els contenidors de la imatge que es crear√†*

*Escriu la l√≠nia que permetr√† que et pugui connectar com a root al servidor SSH remot*

*Escriu la l√≠nia que permetr√† copiar a la imatge una clau p√∫blica RSA que es troba a la mateixa carpeta de Dockerfile.*

*Escriu la l√≠nia que permet obrir el port corresponent a les connexions SSH*

*Quina l√≠nia impedir√† que et connectis per SSH a la m√†quina remota amb un altre usuari que no sigui root ? (pista: consulta man sshd_config)*

Ara crea la imatge corresponent a aquest Dockerfile. S‚Äôha de dir *ubuntu-ssh*

*Comprova primer quantes imatges Docker hi ha ara mateix. Mostra captura pantalla llistat.*

*Quina comanda has fet servir per crear la imatge?*

*Mostra captura de pantalla de la comanda docker images*

*Per qu√® apareixen dues imatges Docker si tu has creat una?*

## Execuci√≥ de docker-compose.yml i configuraci√≥ de /etc/hosts

A continuaci√≥ crearem els contenidors a partir d‚Äôaquesta imatge per√≤ ho farem autom√†ticament executant un fitxer de Docker Compose. Observa docker-compose.yml

*Quants contenidors s‚Äôinstancien en executar aquest fitxer?*

*De quina imatge derivaran?*

*En quina xarxa s‚Äôinclouran?*

Executa aquest script de Docker Compose amb la comanda docker-compose up -d

*De quina manera comproves que les ips assignades a aquests contenidors s√≥n les indicades al fitxer YAML de docker-compose.yml? Mostra una captura de pantalla d‚Äôalmenys la comprovaci√≥ en un dels contenidors.*

*Mostra captura de pantalla als pings des de la VM d‚Äôalmenys un dels contenidors*

Donat que hi ha diversos contenidors i √©s complicat enrecordar totes les ip, aprofitant que docker-compose.yml ha assignat un hostname a cadascun dels contenidors modifica el fitxer */etc/hosts* de la VM per tal de poder pings per hostname.

*Mostra captura de pantalla de /etc/hosts modificat*

*Mostra captura de pantalla de un ping per hostname a un dels contenidors*

## Connexi√≥ per ssh

Recordar que, per facilitar la pr√†ctica,  totes les comandes s‚Äôexecuten com a root, i el repositori el descarreguem a /root. Tal i com has pogut comprovar al *Dockerfile*, aquestes contenidors provenen d‚Äôuna imatge en qu√® s‚Äôha carregat una clau p√∫blica que ten√≠em clonada del repositori. Et demanen que, un cop instanciats aquests contenidors, comprovis que aquesta clau p√∫blica es troba en ells. Recorda que √©s possible executar una comanda remota en un contenidor Docker (no t√© res a veure amb ssh, es fa amb *docker exec*)

*Indica captura de pantalla del contingut del fitxer /root/.ssh/authorized_keys on es troba la clau p√∫blica. Coincideix amb la que es troba a la carpeta docker-env del repositori?*

Tenint en compte que tens disponible  a la carpeta /docker-env del repositori la clau privada complement√†ria a la p√∫blica, i que hem configurat els servidors openssh dels contenidors per tal que acceptin connexions directes per claus de part de l‚Äôusuari root, indica quines accions duus a terme a la VM per tal que amb la comanda ssh root@app1.test entris directament a aquest contenidor.

*Indica clarament les comandes que has fet servir i adjunta les captures de pantalles que cre√Øs convenient per explicar-ho.*

## Ansible. Inventory.

Ansible necessita tenir la seva *llibreta d‚Äôadreces* on trobar tots els servidors que ha d‚Äôaprovisionar. Aquest fitxer s‚Äôanomena **inventari o inventory** i en ell s‚Äôemmagatzemen els hostnames (m√©s exactament els *Fully Qualified Domain Name (FQDN)*) o ips dels servidors on s‚Äôaplicaran les tasques.

Visualitza aquest [video](https://www.youtube.com/watch?v=VgnidinNlkQ&list=PLTd5ehIj0goP2RSCvTiz3-Cko8U6SQV1P&index=3) üìπ de 7 min, en ell s‚Äôexplica on es troba aquest fitxer i com s‚Äôarticula el seu contingut.

*Quina √©s la ruta per defecte t√© aquest fitxer que fa d‚Äôinventari?*

Elimina o comenta el contingut d‚Äôaquest fitxer inventari

Crea en ell dos grups: *loadbalancer *i *webservers*. En el primer posar el hostname (o ip) del loadbalancer, i en el segon el dels dos *webservers*. Aix√≠ podr√†s fer proves contra tots ells o b√© per grups, com veurem a continuaci√≥.

*Mostra captura de pantalla de fitxer /etc/ansible/hosts*

## Primera prova: ping remot

Per comprovar que el controlador Ansible es pot comunicar amb totes les m√†quines de l‚Äôinventari executa

ansible all -m ping

all indica que volem actuar sobre totes les m√†quines de l‚Äôinventari

-m ping indica el nom del m√≤dul Ansible que volem cridar. En aquest cas ping.

Com que √©s possible que sobre un mateix servidor controlador hi hagis diversos usuaris amb els seus propis inventories, podr√≠em voler cridar Ansible passant un inventory diferent del que troba a la ruta per defecte. Copia aquest /etc/ansible/hosts a la ruta /root/ansible-playground, amb el nom hosts-dev i executa la mateixa crida anterior per√≤ passant per par√†metre el fitxer inventari que acabem de copiar. D‚Äôaquesta manera no estem permanentment lligats al de /etc/ansible/hosts.

ansible all -m ping -i /root/ansible-playground/hosts-dev

Comprova que pots fer pings per grups, substituint el terme **all **per cada un dels grups creats a inventory.

Tamb√© pots comprovar que l‚Äôinventory que s‚Äôestat llegint per defecte √©s el correcte executant:

ansible --list-hosts webservers

ansible --list-hosts loadbalancer

*Mostra captura de pantalla de Ansible m√≤dul ping a grup loadbalancer de inventory hosts-dev*

*Mostra captura de pantalla de Ansible m√≤dul ping a grup webservers de inventory hosts-dev*

## El fitxer de configuraci√≥ ansible.cfg

Molts programes de Linux tenen el seu fitxer de text pla amb les opcions de configuraci√≥ (per ex. Samba, OpenSSH, etc.). Ansible tamb√©. El que passa √©s que, segons la [documentaci√≥](https://docs.ansible.com/ansible/latest/reference_appendices/config.html#ansible-configuration-settings) aquest fitxer de configuraci√≥ ansible.cfg tamb√© pot residir en diverses localitzacions i hi ha unes prioritats establertes sobre les variables definides en aquests fitxer segons on es trobi.

Trobem un d‚Äôexemple a /etc/ansible/ansible.cfg.

En aquest fitxer ansible.cfg hauries de fer constar la clau privada i l‚Äôusuari si vols connectar Ansible contra una m√†quina que no tingu√©s configurat el reconeixement de claus com ja tenim muntat en el nostre projecte.

Nosaltres el que farem ser√† modificar el fitxer /etc/ansible/ansible.cfg. Recordeu que en aquesta mena de fitxer els valors comentats s√≥n els que es troben per defecte. Descomentarem la l√≠nia #inventory i hi indicarem la ruta al nostre propi hosts-dev:

inventory      = /root/ansible-playground/hosts-dev
Gr√†cies a aquest canvi podrem dur a terme les mateixes operacions anteriors per√≤ sense necessitat d‚Äôindicar la ruta de l‚Äôinventari.

*Mostra captura de pantalla de Ansible m√≤dul ping a grup loadbalancer, per√≤ aquesta vegada sense indica l‚Äôargument de la ruta a l‚Äôinventari*

<table>
  <tr>
    <td>How do you stop Ansible from creating .retry files in the home directory? üò´

Si Ansible no ha aconseguit executar correctament un playbook, per defecte crea a la mateixa carpeta un arxiu d‚Äôextensi√≥ .retry amb el mateix nom del playbook. Aix√≤ pot ser molest en determinats contextos i alguns desenvolupadors prefereixen que aquests fitxers no es cre√Øn. Cerca per internet la soluci√≥ per desactivar aquesta caracter√≠stica en el fitxer de configuraci√≥ que hem tractat en aquest apartat. √âs molt senzilla!üëç
</td>
  </tr>
</table>


*Explica la soluci√≥ aportada per desactivar els fitxers .retry.*

## Tasks

Les **tasks **s√≥n les comandes m√©s b√†siques que enviem a les m√†quines del nostre inventari, i que seran executades a trav√©s de les respectives connexions ssh. De fet l‚Äôexemple anterior de ping ja n‚Äôera un i prenent-lo com a model podem veure a la il¬∑lustraci√≥ com s‚Äôestructura qualsevol task. 

El retorn d‚Äôaquesta comanda v√© donat pel resultat de l‚Äôexecuci√≥ en cadascuna de les m√†quines escollides.  Si tot ha anat b√© ser√† SUCCESS a totes tres.

Atura un dels webservers amb la comanda *docker stop* *nomservidor [tamb√© pots fer servir containerid] *que trobar√†s al resultat de la comanda *docker ps*.

*Mostra captura de pantalla amb comanda i resultats quan tornes a fer un ping al grup webservers per√≤ amb un dels dos apagats.*

Recorda reiniciar el contenidor id amb la comanda docker start

Ansible disposa d‚Äôun cat√†leg de m√≤duls, que pots consultar [aqu√≠](https://docs.ansible.com/ansible/latest/modules/modules_by_category.html) que ens permet executar moltes ordres. Un dels m√≤duls m√©s conegut √©s el de **shell**, que ens permet executar una ordre de la shell remota. Exemple:

ansible -m shell -a "uname" webservers:loadbalancer

*Mostra captura de pantalla*

*rc=0* √©s el return code, que en aquest √©s d‚Äô√®xit.

√âs molt senzill provocar una comanda d‚Äôerror. Fes servir el mateix m√≤dul shell per√≤ ara llegint amb *cat *un fitxer inexistent en les m√†quines remotes (inventa‚Äôt un nom de fitxer aleatori, segur que no existeix en els filesystems de les m√†quines remotes)

*Mostra captura de pantalla amb comanda i resultats quan tornes a fer un ping a totes les m√†quines de l‚Äôinventori*

Tot i que les tasks siguin una manera senzilla automatitzar accions contra m√†quines remote o com a m√≠nim de provar l‚Äôentorn, la veritat √©s que Ansible proveeix d‚Äôeines encara m√©s sofisticades per poder-ho fer: els **playbooks**.

<table>
  <tr>
    <td>üììRecorda:
</td>
  </tr>
</table>


## Playbooks

Les tasques es troben habitualment formant part de *playbooks*, uns fitxers on aquestes tasques consten seq√ºencialment i als quals podem afegir altres elements com per ex. variables.

Els playbooks segueixen una *sintaxi YAML*. Podem transformar la tasca ping anterior en un playbook com indica la il¬∑lustraci√≥. Fes ho, el fitxer *playbook *tal i com pots veure s‚Äôha d‚Äôanomenar *ping.yml* (crea una nova carpeta en el repositori que es digui /root/ansible-playground/playbooks, i inclou-lo all√†)  i *mostra la captura de pantalla de la seva execuci√≥.*

 

En realitat els playbooks que trobar√†s en els entorns de treball contenen diverses tasques, i estaran estructurats molt sovint d‚Äôuna manera semblant perqu√® gaireb√© tots ells actualitzen, instal¬∑len, configuren i comproven l‚Äôstatus del servei que acaben d‚Äôimplementar.

Aquesta estructura tan habitual tamb√© es pot resumir en:

* Gesti√≥ de paquets

* Configuraci√≥ de la infrastructura

* Service Handlers

Els **handlers **s√≥n tasques d‚ÄôAnsible que nom√©s s‚Äôexecuten quan les crida un altra tasca, i fer ho fan a partir d‚Äôun event. Un handler molt habitual √©s aquell que ordena iniciar un servei pr√®viament instal¬∑lat. En aquesta il¬∑lustraci√≥, que mostra la instal¬∑laci√≥ i arrencada d‚Äôun servidor Apache,  pots veure les tres fases per le sol passar un script d‚ÄôAnsible i de quina manera la tasca, mitjan√ßant la propietat **notify**, la tasca que instal¬∑la nGinx acaba cridant el handler que el reinicia.

![image alt text](images/image_5.png)

## ‚ûÄ Desplegament automatitzat d‚Äôun servidor web de dos nodes amb un balancejador de c√†rrega (Apache i PHP)

![image alt text](images/image_6.png)

A la mateixa carpeta de playbooks crearem un playbook anomenat apt-update.yml que dugui a terme l‚Äôactualitzaci√≥ dels repositoris de paquets a la darrera versi√≥:

![image alt text](images/image_7.png)

*Crida aquest playbook i comprova que funciona correctament. Mostra captura de pantalla. Recorda que un fitxer YAML no heu de fer servir tabulacions.*

Continuem amb la configuraci√≥ de paquets, ara amb la **instal¬∑laci√≥ de Apache2** a tots els nodes (al loadbalancer el farem servir en mode reverse proxy). A m√©s als webservers instal¬∑larem php, donat que allotjarem p√†gines din√†miques. Crea a la mateixa carpeta el playbook *install-services.yml*

![image alt text](images/image_8.png)

Executa una primera vegada per comprovar que funciona i a continuaci√≥ executa una segona vegada. Fixa‚Äôt, en l‚Äôapartat de resultats en PLAY RECAP, en concret en el camp **changed**

*Indica quina difer√®ncia hi ha en aquest camp del resultat la primera vegada que executes aquest playbook i les posteriors.*

El valor d‚Äôaquest camp est√† relacionat amb la caracter√≠stica de la **idempot√®ncia **que comparteix Ansible amb altres llenguatges declaratius. Ansible √©s idempotent perqu√® la seva declaraci√≥ no executa processos indicats per l‚Äôusuari, sin√≥ que s‚Äôencarrega de gestionar el sistema per tal que quedi en l‚Äô**estat** indicat al playbook. En els resultats que es mostren per consola en l‚Äôexecuci√≥ TASK [Gathering Facts] √©s la fase en qu√® Ansible comprova com es troba el target. Si ja es troba en l‚Äôestat espec√≠ficat pel playbook, no executar√† res. De si s‚Äôhan produ√Øt o no modificacions respecte a com estava el remot, dona compte el camp *changed*.

*Explica i mostra amb captures de pantalla de quina manera comproves que les m√†quines webservers tenen Apache2 funcionant*

## ‚ûÅ Upload index.php

Finalitzarem la configuraci√≥ fent servir dos m√≤duls m√©s molt coneguts d‚ÄôAnsible: el que permet copiar fitxers (el farem servir per copiar un* index.php* als dos webservers) i el que permet editar fitxers remots afegint una l√≠nia.

Creem un fitxer index.php d‚Äôexemple a la carpeta ansible-playground, amb un codi que permet :

<?

// Show all information, defaults to INFO_ALL

echo "Aquesta es la pagina de prova Ansible PHP";

$ip_server = $_SERVER['SERVER_ADDR'];

echo "Server IP Address is: $ip_server";

?>

I a continuaci√≥ crea un playbook anomenat *setup-app.yml* que contingui una tasca que permeti copiar el fitxer index.php als webservers, fent servir el m√≤dul *copy*: fixa‚Äôt que el fitxer que puja √©s el creat anteriorment a la carpeta superior:

![image alt text](images/image_9.png)

*Executa aquest playbook i comprova que s‚Äôha copiat en tots dos servidors. Mostra captures de pantalla.*

## Configuraci√≥ de php.ini. Un exemple del m√≤dul Ansible d‚Äôedici√≥ de l√≠nies de fitxers

Un dels m√≤duls m√©s coneguts d‚ÄôAnsible √©s [lineinfile](https://docs.ansible.com/ansible/latest/modules/lineinfile_module.html), que permet fer edicions de fitxers remots modificant l√≠nies, afegint-ne de noves o esborrant-ne.

En aquest cas el farem servir per al nostre projecte perqu√® ens interessa que la configuraci√≥ de php dels webservers permeti els anomenats short tags, de forma que pugui comen√ßar la p√†gina amb <? en lloc de <?php. Podeu provar que aix√≤ ara mateix no es permet.

El playbook, al mateix directori que la resta, que cridaria a aquest m√≤dul √©s:

# setup-app.yml

  - hosts: webservers

    tasks:

      - name: Upload application file

        copy:

          src: ../index.php

          dest: /var/www/html

          mode: 0755

      - name: Configure php.ini file

        lineinfile:

          path: /etc/php/7.2/apache2/php.ini

          regexp: ^short_open_tag

          line: 'short_open_tag=On'

        notify: restart apache

    handlers:

      - name: restart apache

        service: name=apache2 state=restarted

*Mostra captura de pantalla d‚Äôexecuci√≥ d‚Äôaquest playbook i mostra captura de pantalla de que la p√†gina funciona en algun dels dos webservers.*

## Configuraci√≥ de loadbalancer

*mod_proxy_balancer *√©s l‚Äôextensi√≥ d‚ÄôApache que permet fer balanceig de c√†rrega. Pots trobar els detalls de la configuraci√≥ a la [p√†gina oficial](https://httpd.apache.org/docs/2.4/mod/mod_proxy_balancer.html). B√†sicament el que necessitem √©s que el fitxer de configuraci√≥ d‚Äôaquesta extensi√≥ hi constin les ips dels nodes als quals redirigir√† les peticions:

 

Podr√≠em substituir <IP_ADDRESS> per les ips dels dos webservers, acabar de completar aquest fitxer de configuraci√≥ i funcionaria. Tanmateix, aquestes ips serien fixes, i si canviessin les ips del fitxer inventari, ja no servirien. Seria molt interessant que l‚Äôexpressi√≥ BalancerMember es gener√©s de manera din√†mica, en un bucle, a partir de la lectura del fitxer que fa d‚Äôinventari.

Ansible permet crear arxius de forma din√†mica a partir d‚Äôuna plantilla escrita en **Jinja2**. Si creem la plantilla de configuraci√≥ en aquest format, el que pujar√† realment al node que fa de node balancer √©s la plantilla amb les variables de les ips substitu√Ødes pels valors que trobar√† al fitxer inventari. D‚Äôaquesta manera es guanya en la capacitat d‚Äôautomatitzar aquest desplegament, donat que si m√©s endavant canvien les ips, nom√©s s‚Äôha de tocar l‚Äôinventari, cap altre fitxer de configuraci√≥ m√©s.

Aquest fitxer inclou altres directives pr√≤pies d‚ÄôApache com ara la possibilitat d‚Äôhabilitar un gestor web del load-balancer, a la url /balancer-manager per tal de mostrar el nombre de redireccions fetes. Pots trobar m√©s informaci√≥ sobre la configuraci√≥ del balancer d‚ÄôApache a  [https://httpd.apache.org/docs/2.4/howto/reverse_proxy.html](https://httpd.apache.org/docs/2.4/howto/reverse_proxy.html)

Crea una carpeta *config *al nivell superior a la carpeta *ansible-playground, i crea el fitxer lb-config.j2*.

# config/lb-config.j2

ProxyRequests off

<Proxy balancer://webcluster >

  {% for hosts in groups['webservers'] %}

    BalancerMember http://{{hostvars[hosts]['inventory_hostname']}}

  {% endfor %}

    ProxySet lbmethod=byrequests

</Proxy>

<Location "/balancer-manager">

    SetHandler balancer-manager

    Order Deny,Allow

    Allow from all

</Location>

ProxyPass /balancer-manager !

ProxyPass / balancer://webcluster/

ProxyPassReverse / balancer://webcluster/

El playbook setup-lb.yml ser√† l‚Äôencarregat de deixar el fitxer de configuraci√≥ al directori mods-enabled d‚ÄôApache de node loadbalancer,

# playbooks/setup-lb.yml

  - hosts: loadbalancer

    tasks:

    - name: Enable proxy module

      apache2_module: name=proxy identifier=proxy state=present

    - name: Enable http_proxy module

      apache2_module: name=proxy_http identifier=proxy_http state=present

    - name: Enable proxy_balancer

      apache2_module: name=proxy_balancer identifier=proxy_balancer_module state=present

    - name: Enable lbmethod_byrequests module

      apache2_module: name=lbmethod_byrequests identifier=lbmethod_byrequests state=present

    - name: Creating template

      template:

        src: ../config/lb-config.j2

        dest: /etc/apache2/conf-enabled/lb.conf

    - name: restart apache

      service: name=apache2 state=restarted

*Com es diu la tasca corresponent la configuraci√≥ del load balancer?*

*Qu√® fan les tasques del pla anteriors a la del load balancer?*

Un cop tenim aquests dos fitxers podem executar aquest playbook de configuraci√≥ del *loadbalancer *amb:

ansible-playbook setup-lb.yml

Podr√†s veure la web ja que el *Vagrantfile *t√© una redirecci√≥ del port 80 de la ip de loadbalancer al 80 de l‚Äôamfitri√≥.

*Executa‚Äôl i comprova que s‚Äôha copiat en servidor loadbalancer, en la ruta indica al playbook. Mostra captura de pantalla.*

*Respon: gr√†cies a quina l√≠nia espec√≠fica de Dockerfile pots veure des de la VM la p√†gina curl localhost:80/index.php. Mostra captura de pantalla.*

*Indica una altra adre√ßa per accedir ***_des de la shell de VM_*** al load balancer, tamb√© amb curl. Mostra captura de pantalla.*

*Mostra captura de pantalla de **[http://ipvagrantmachine/index.ph*p](http://ipvagrantmachine/index.php)

*Mostra captura de pantalla del load-balancer manager. Si fas clic sobre els enlla√ßos de WorkerURL veur√†s que pots modificar la configuraci√≥ Load Factor. Investiga quin Load Factor has de posar a app1.test per tal que registri el doble de hits que app2.test. Mostra captura de pantalla del canvi.*

## ‚ûÇ Handlers

Per qu√® reiniciar el servei Apache‚Ä¶ si no hi ha hagut canvis? *Handlers al rescat*.üôã

Sovint executem un playbook que al final reinicia un servei, per exemple Apache. Tanmateix, si analitzem el log, veurem que el canvi que volia efectuar, per exemple en un fitxer de configuraci√≥ del servei, realment no s‚Äôha efectuat‚Ä¶ per qu√® aleshores reiniciar Apache?

Per evitar aquestes situacions es van crear els handlers. Un handler √©s una task, com qualsevol altra, que nom√©s s‚Äôexecutar√† si es cridar des d‚Äôuna altra.

Anem a aplicar aquest concepte al nostre projecte.

Recorda que en el playbook setup-app.yml abans hav√≠em modificat el php.ini per tal de permetre obrir etiquetes en mode ‚Äò<?‚Äô. Cada vegada que execut√†vem aquella tasca que afegia una l√≠nia al final ten√≠em una altra que reiniciava apache. Doncs b√©, ara indicarem amb un handler que nom√©s es reinic√Øi apache si ho notifica la tasca de l‚Äôetiqueta a php.ini. 

      - name: Configure php.ini file

        lineinfile:

          path: /etc/php/7.2/apache2/php.ini

          regexp: ^short_open_tag

          line: 'short_open_tag=On'

        notify: restart apache

    handlers:

      - name: restart apache

        service: name=apache2 state=restarted

Observa el log de sortida d‚ÄôAnsible en successives execucions. La primera vegada surt el log de reinici d‚ÄôApache.

*Mostra captura sortida Ansible amb reinici servidor.*

En successives execucions no hauria de sortir.

Entra en app1.test i executa:

grep resuming /var/log/apache2/error.log

*Respon a qu√® correspon aquestes l√≠nies de sortida.*

## Tots els playbooks en un fitxer

Es poden executar tots els playbooks a la vegada important-los en un fitxer

#playbooks/all-playbooks.yml

  - import_playbook: apt-update.yml

  - import_playbook: install-services.yml

  - import_playbook: setup-app.yml

  - import_playbook: setup-lb.yml

*Puja al teu repositori de GitHub la pr√†ctica completada i indica la url:*

*‚Ä¶...*

L‚Äôaspecte final del projecte webservers i reverse proxy amb Ansible hauria de ser aquest:

![image alt text](images/image_10.png)

